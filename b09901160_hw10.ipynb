{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbwhere/pbwhere.github.io/blob/main/b09901160_hw10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 10 - Adversarial Attack**"
      ],
      "metadata": {
        "id": "H9m2AbpHC9vS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enviroment & Download\n",
        "\n",
        "We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."
      ],
      "metadata": {
        "id": "k0G8g5KuDBzU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMK1RhUQCz1e",
        "outputId": "5b7a4b32-4383-46d9-aa46-556bdf6d5331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorchcv\n",
            "  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.4/532.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorchcv) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorchcv) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorchcv) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorchcv) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pytorchcv) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorchcv) (3.4)\n",
            "Installing collected packages: pytorchcv\n",
            "Successfully installed pytorchcv-0.0.67\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.10.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.25.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.0.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw\n",
            "To: /content/data.zip\n",
            "100% 490k/490k [00:00<00:00, 129MB/s]\n",
            "Archive:  ./data.zip\n",
            "   creating: data/\n",
            "   creating: data/deer/\n",
            " extracting: data/deer/deer13.png    \n",
            " extracting: data/deer/deer6.png     \n",
            " extracting: data/deer/deer11.png    \n",
            " extracting: data/deer/deer2.png     \n",
            " extracting: data/deer/deer10.png    \n",
            " extracting: data/deer/deer16.png    \n",
            " extracting: data/deer/deer9.png     \n",
            " extracting: data/deer/deer20.png    \n",
            " extracting: data/deer/deer15.png    \n",
            " extracting: data/deer/deer19.png    \n",
            " extracting: data/deer/deer5.png     \n",
            " extracting: data/deer/deer14.png    \n",
            " extracting: data/deer/deer4.png     \n",
            " extracting: data/deer/deer8.png     \n",
            " extracting: data/deer/deer12.png    \n",
            " extracting: data/deer/deer1.png     \n",
            " extracting: data/deer/deer7.png     \n",
            " extracting: data/deer/deer17.png    \n",
            " extracting: data/deer/deer18.png    \n",
            " extracting: data/deer/deer3.png     \n",
            "   creating: data/horse/\n",
            " extracting: data/horse/horse9.png   \n",
            " extracting: data/horse/horse1.png   \n",
            " extracting: data/horse/horse16.png  \n",
            " extracting: data/horse/horse15.png  \n",
            " extracting: data/horse/horse19.png  \n",
            " extracting: data/horse/horse14.png  \n",
            " extracting: data/horse/horse10.png  \n",
            " extracting: data/horse/horse7.png   \n",
            " extracting: data/horse/horse2.png   \n",
            " extracting: data/horse/horse6.png   \n",
            " extracting: data/horse/horse20.png  \n",
            " extracting: data/horse/horse5.png   \n",
            " extracting: data/horse/horse18.png  \n",
            " extracting: data/horse/horse12.png  \n",
            " extracting: data/horse/horse13.png  \n",
            " extracting: data/horse/horse17.png  \n",
            " extracting: data/horse/horse4.png   \n",
            " extracting: data/horse/horse11.png  \n",
            " extracting: data/horse/horse8.png   \n",
            " extracting: data/horse/horse3.png   \n",
            "   creating: data/ship/\n",
            " extracting: data/ship/ship10.png    \n",
            " extracting: data/ship/ship14.png    \n",
            " extracting: data/ship/ship9.png     \n",
            " extracting: data/ship/ship20.png    \n",
            " extracting: data/ship/ship5.png     \n",
            " extracting: data/ship/ship8.png     \n",
            " extracting: data/ship/ship19.png    \n",
            " extracting: data/ship/ship16.png    \n",
            " extracting: data/ship/ship13.png    \n",
            " extracting: data/ship/ship6.png     \n",
            " extracting: data/ship/ship17.png    \n",
            " extracting: data/ship/ship1.png     \n",
            " extracting: data/ship/ship12.png    \n",
            " extracting: data/ship/ship2.png     \n",
            " extracting: data/ship/ship3.png     \n",
            " extracting: data/ship/ship15.png    \n",
            " extracting: data/ship/ship4.png     \n",
            " extracting: data/ship/ship7.png     \n",
            " extracting: data/ship/ship11.png    \n",
            " extracting: data/ship/ship18.png    \n",
            "   creating: data/frog/\n",
            " extracting: data/frog/frog10.png    \n",
            " extracting: data/frog/frog4.png     \n",
            " extracting: data/frog/frog5.png     \n",
            " extracting: data/frog/frog20.png    \n",
            " extracting: data/frog/frog15.png    \n",
            " extracting: data/frog/frog3.png     \n",
            " extracting: data/frog/frog1.png     \n",
            " extracting: data/frog/frog14.png    \n",
            " extracting: data/frog/frog2.png     \n",
            " extracting: data/frog/frog19.png    \n",
            " extracting: data/frog/frog7.png     \n",
            " extracting: data/frog/frog11.png    \n",
            " extracting: data/frog/frog17.png    \n",
            " extracting: data/frog/frog18.png    \n",
            " extracting: data/frog/frog12.png    \n",
            " extracting: data/frog/frog16.png    \n",
            " extracting: data/frog/frog8.png     \n",
            " extracting: data/frog/frog13.png    \n",
            " extracting: data/frog/frog6.png     \n",
            " extracting: data/frog/frog9.png     \n",
            "   creating: data/airplane/\n",
            " extracting: data/airplane/airplane3.png  \n",
            " extracting: data/airplane/airplane4.png  \n",
            " extracting: data/airplane/airplane2.png  \n",
            " extracting: data/airplane/airplane9.png  \n",
            " extracting: data/airplane/airplane20.png  \n",
            " extracting: data/airplane/airplane18.png  \n",
            " extracting: data/airplane/airplane19.png  \n",
            " extracting: data/airplane/airplane10.png  \n",
            " extracting: data/airplane/airplane6.png  \n",
            " extracting: data/airplane/airplane13.png  \n",
            " extracting: data/airplane/airplane16.png  \n",
            " extracting: data/airplane/airplane14.png  \n",
            " extracting: data/airplane/airplane11.png  \n",
            " extracting: data/airplane/airplane1.png  \n",
            " extracting: data/airplane/airplane17.png  \n",
            " extracting: data/airplane/airplane7.png  \n",
            " extracting: data/airplane/airplane15.png  \n",
            " extracting: data/airplane/airplane5.png  \n",
            " extracting: data/airplane/airplane8.png  \n",
            " extracting: data/airplane/airplane12.png  \n",
            "   creating: data/bird/\n",
            " extracting: data/bird/bird9.png     \n",
            " extracting: data/bird/bird12.png    \n",
            " extracting: data/bird/bird10.png    \n",
            " extracting: data/bird/bird11.png    \n",
            " extracting: data/bird/bird5.png     \n",
            " extracting: data/bird/bird8.png     \n",
            " extracting: data/bird/bird4.png     \n",
            " extracting: data/bird/bird3.png     \n",
            " extracting: data/bird/bird7.png     \n",
            " extracting: data/bird/bird18.png    \n",
            " extracting: data/bird/bird14.png    \n",
            " extracting: data/bird/bird13.png    \n",
            " extracting: data/bird/bird2.png     \n",
            " extracting: data/bird/bird15.png    \n",
            " extracting: data/bird/bird17.png    \n",
            " extracting: data/bird/bird19.png    \n",
            " extracting: data/bird/bird16.png    \n",
            " extracting: data/bird/bird6.png     \n",
            " extracting: data/bird/bird20.png    \n",
            " extracting: data/bird/bird1.png     \n",
            "   creating: data/cat/\n",
            " extracting: data/cat/cat6.png       \n",
            " extracting: data/cat/cat1.png       \n",
            " extracting: data/cat/cat7.png       \n",
            " extracting: data/cat/cat19.png      \n",
            " extracting: data/cat/cat5.png       \n",
            " extracting: data/cat/cat9.png       \n",
            " extracting: data/cat/cat17.png      \n",
            " extracting: data/cat/cat2.png       \n",
            " extracting: data/cat/cat16.png      \n",
            " extracting: data/cat/cat10.png      \n",
            " extracting: data/cat/cat4.png       \n",
            " extracting: data/cat/cat18.png      \n",
            " extracting: data/cat/cat13.png      \n",
            " extracting: data/cat/cat11.png      \n",
            " extracting: data/cat/cat20.png      \n",
            " extracting: data/cat/cat15.png      \n",
            " extracting: data/cat/cat8.png       \n",
            " extracting: data/cat/cat14.png      \n",
            " extracting: data/cat/cat3.png       \n",
            " extracting: data/cat/cat12.png      \n",
            "   creating: data/automobile/\n",
            " extracting: data/automobile/automobile17.png  \n",
            " extracting: data/automobile/automobile11.png  \n",
            " extracting: data/automobile/automobile5.png  \n",
            " extracting: data/automobile/automobile10.png  \n",
            " extracting: data/automobile/automobile20.png  \n",
            " extracting: data/automobile/automobile2.png  \n",
            " extracting: data/automobile/automobile6.png  \n",
            " extracting: data/automobile/automobile1.png  \n",
            " extracting: data/automobile/automobile19.png  \n",
            " extracting: data/automobile/automobile7.png  \n",
            " extracting: data/automobile/automobile16.png  \n",
            " extracting: data/automobile/automobile3.png  \n",
            " extracting: data/automobile/automobile14.png  \n",
            " extracting: data/automobile/automobile12.png  \n",
            " extracting: data/automobile/automobile9.png  \n",
            " extracting: data/automobile/automobile4.png  \n",
            " extracting: data/automobile/automobile8.png  \n",
            " extracting: data/automobile/automobile13.png  \n",
            " extracting: data/automobile/automobile18.png  \n",
            " extracting: data/automobile/automobile15.png  \n",
            "   creating: data/dog/\n",
            " extracting: data/dog/dog9.png       \n",
            " extracting: data/dog/dog2.png       \n",
            " extracting: data/dog/dog15.png      \n",
            " extracting: data/dog/dog8.png       \n",
            " extracting: data/dog/dog3.png       \n",
            " extracting: data/dog/dog19.png      \n",
            " extracting: data/dog/dog12.png      \n",
            " extracting: data/dog/dog7.png       \n",
            " extracting: data/dog/dog17.png      \n",
            " extracting: data/dog/dog11.png      \n",
            " extracting: data/dog/dog16.png      \n",
            " extracting: data/dog/dog20.png      \n",
            " extracting: data/dog/dog4.png       \n",
            " extracting: data/dog/dog5.png       \n",
            " extracting: data/dog/dog14.png      \n",
            " extracting: data/dog/dog18.png      \n",
            " extracting: data/dog/dog10.png      \n",
            " extracting: data/dog/dog1.png       \n",
            " extracting: data/dog/dog13.png      \n",
            " extracting: data/dog/dog6.png       \n",
            "   creating: data/truck/\n",
            " extracting: data/truck/truck1.png   \n",
            " extracting: data/truck/truck18.png  \n",
            " extracting: data/truck/truck9.png   \n",
            " extracting: data/truck/truck4.png   \n",
            " extracting: data/truck/truck14.png  \n",
            " extracting: data/truck/truck8.png   \n",
            " extracting: data/truck/truck12.png  \n",
            " extracting: data/truck/truck15.png  \n",
            " extracting: data/truck/truck2.png   \n",
            " extracting: data/truck/truck5.png   \n",
            " extracting: data/truck/truck3.png   \n",
            " extracting: data/truck/truck10.png  \n",
            " extracting: data/truck/truck17.png  \n",
            " extracting: data/truck/truck20.png  \n",
            " extracting: data/truck/truck19.png  \n",
            " extracting: data/truck/truck13.png  \n",
            " extracting: data/truck/truck7.png   \n",
            " extracting: data/truck/truck6.png   \n",
            "  inflating: data/truck/truck16.png  \n",
            " extracting: data/truck/truck11.png  \n"
          ]
        }
      ],
      "source": [
        "# set up environment\n",
        "!pip install pytorchcv\n",
        "!pip install imgaug\n",
        "\n",
        "# download\n",
        "!gdown --id 1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw --output data.zip\n",
        "\n",
        "# if the above link isn't available, try this one\n",
        "# !wget https://www.dropbox.com/s/lbpypqamqjpt2qz/data.zip\n",
        "\n",
        "# unzip\n",
        "!unzip ./data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ./data.zip"
      ],
      "metadata": {
        "id": "-a6naDouEWUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 8\n",
        "\n",
        "def same_seeds(seed):\n",
        "\t  torch.manual_seed(seed)\n",
        "\t  if torch.cuda.is_available():\n",
        "\t\t    torch.cuda.manual_seed(seed)\n",
        "\t\t    torch.cuda.manual_seed_all(seed)\n",
        "\t  np.random.seed(seed)\n",
        "\t  random.seed(seed)\n",
        "\t  torch.backends.cudnn.benchmark = False\n",
        "\t  torch.backends.cudnn.deterministic = True\n",
        "same_seeds(0) "
      ],
      "metadata": {
        "id": "SaEEx0Y3DMdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Settings \n",
        "#### **[NOTE]**: Don't change the settings here, or your generated image might not meet the constraint.\n",
        "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
        "\n",
        "* Explaination (optional)\n",
        "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
        "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
        "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
        "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
        "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
        "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
      ],
      "metadata": {
        "id": "Z8mIr7c0DPsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the mean and std are the calculated statistics from cifar_10 dataset\n",
        "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
        "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
        "\n",
        "# convert mean and std to 3-dimensional tensors for future operations\n",
        "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
        "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
        "\n",
        "epsilon = 8/255/std"
      ],
      "metadata": {
        "id": "IBdYgS2DDNL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = './data' # directory for storing benign images\n",
        "# benign images: images which do not contain adversarial perturbations\n",
        "# adversarial images: images which include adversarial perturbations"
      ],
      "metadata": {
        "id": "AjNkQLoaDWba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."
      ],
      "metadata": {
        "id": "sNf-LoODDZXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
        "])\n",
        "\n",
        "class AdvDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.names = []\n",
        "        '''\n",
        "        data_dir\n",
        "        ├── class_dir\n",
        "        │   ├── class1.png\n",
        "        │   ├── ...\n",
        "        │   ├── class20.png\n",
        "        '''\n",
        "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
        "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
        "            self.images += images\n",
        "            self.labels += ([i] * len(images))\n",
        "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.transform(Image.open(self.images[idx]))\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "    def __getname__(self):\n",
        "        return self.names\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "adv_set = AdvDataset(root, transform=transform)\n",
        "adv_names = adv_set.__getname__()\n",
        "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f'number of images = {adv_set.__len__()}')"
      ],
      "metadata": {
        "id": "lV7rbnD5DarR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0708f3a8-bf23-4b72-e6de-b1ee5adf745b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images = 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils -- Benign Images Evaluation"
      ],
      "metadata": {
        "id": "C9D7eakEDflF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to evaluate the performance of model on benign images\n",
        "def epoch_benign(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    train_acc, train_loss = 0.0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        yp = model(x)\n",
        "        loss = loss_fn(yp, y)\n",
        "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "byE4VH3uDduA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils -- Attack Algorithm"
      ],
      "metadata": {
        "id": "D3L_qtufDk4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform fgsm attack\n",
        "import tensorflow as tf\n",
        "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
        "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
        "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
        "    loss.backward() # calculate gradient\n",
        "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
        "    grad = x_adv.grad.detach()\n",
        "    x_adv = x_adv + epsilon * grad.sign()\n",
        "    return x_adv\n",
        "\n",
        "# alpha and num_iter can be decided by yourself\n",
        "alpha = 0.8/255/std\n",
        "\n",
        "def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n",
        "    x_adv = x.detach().clone()\n",
        "    # initialize\n",
        "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
        "    loss.backward() # calculate gradient\n",
        "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
        "    grad = x_adv.grad.detach()\n",
        "    x_adv = x_adv + epsilon * grad.sign()\n",
        "    ################ TODO: Medium baseline #######################\n",
        "    # write a loop with num_iter times\n",
        "    for i in range(1, num_iter):\n",
        "      # TODO: Each iteration, execute fgsm\n",
        "      x_adv = fgsm(model, x_adv, y, loss_fn, alpha)\n",
        "      # clip new x_adv back to [x-epsilon, x+epsilon]\n",
        "      x_adv = torch.min(torch.max(x_adv, x-epsilon), x+epsilon)\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "def mifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20, decay=0.3):\n",
        "    x_adv = x.detach().clone().to(device)\n",
        "    # initialze momentum tensor\n",
        "    momentum = torch.zeros_like(x).detach().to(device)\n",
        "    \n",
        "    ################ TODO: Strong baseline ####################\n",
        "    grad = 0\n",
        "    for i in range(num_iter):\n",
        "      if torch.rand(1).item() >= 0.6:\n",
        "        #resize img to rnd X rnd\n",
        "        rnd = torch.randint(29, 33, (1,)).item()\n",
        "        x_adv = transforms.Resize((rnd, rnd))(x_adv)\n",
        "        #padding img to 32 X 32 with 0\n",
        "        left = torch.randint(0, 32 - rnd + 1, (1,)).item()\n",
        "        top = torch.randint(0, 32 - rnd + 1, (1,)).item()\n",
        "        right = 32 - rnd - left\n",
        "        bottom = 32 - rnd - top\n",
        "        x_adv = transforms.Pad([left, top, right, bottom])(x_adv)\n",
        "\n",
        "      x_adv = x_adv.detach().clone()\n",
        "      x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "      loss = loss_fn(model(x_adv), y) # calculate loss\n",
        "      loss.backward() # calculate gradient\n",
        "      \n",
        "      # TODO: Refer to the algorithm of MI-FGSM\n",
        "      # Calculate the momentum and update\n",
        "      grad =  decay * grad + x_adv.grad.detach() / torch.norm(x_adv.grad.detach())\n",
        "      x_adv = x_adv + alpha * grad.sign()\n",
        "      x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon) # clip new x_adv back to [x-epsilon, x+epsilon]\n",
        "\n",
        "\n",
        "    return x_adv"
      ],
      "metadata": {
        "id": "odTOhtrtDklT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils -- Attack\n",
        "* Recall\n",
        "  * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
        "  * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
        "\n",
        "* Inverse function\n",
        "  * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
        "  * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
        "\n",
        "* Special Noted\n",
        "  * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
        "  * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
      ],
      "metadata": {
        "id": "0o9ww4s1DrEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform adversarial attack and generate adversarial examples\n",
        "def gen_adv_examples(model, loader, attack, loss_fn):\n",
        "    model.eval()\n",
        "    adv_names = []\n",
        "    train_acc, train_loss = 0.0, 0.0\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n",
        "        yp = model(x_adv)\n",
        "        loss = loss_fn(yp, y)\n",
        "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "        # store adversarial examples\n",
        "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
        "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
        "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
        "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
        "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
        "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
        "\n",
        "# create directory which stores adversarial examples\n",
        "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
        "    if os.path.exists(adv_dir) is not True:\n",
        "        _ = shutil.copytree(data_dir, adv_dir)\n",
        "    for example, name in zip(adv_examples, adv_names):\n",
        "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
        "        im.save(os.path.join(adv_dir, name))"
      ],
      "metadata": {
        "id": "rbtfv7rjDrvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model / Loss Function\n",
        "\n",
        "Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Other kinds of models are prohibited, and it will be considered to be cheating if you use them. \n",
        "\n",
        "Note: Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."
      ],
      "metadata": {
        "id": "rbLBR4bjDu7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is used to check whether you use models pretrained on cifar10 instead of other datasets\n",
        "def model_checker(model_name):\n",
        "  assert ('cifar10' in model_name) and ('cifar100' not in model_name), 'The model selected is not pretrained on cifar10!'"
      ],
      "metadata": {
        "id": "xCKMshb08I1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ BOSS BASELINE ######################\n",
        "class ensembleNet(nn.Module):\n",
        "    def __init__(self, model_names, device='cuda'):\n",
        "        super(ensembleNet, self).__init__()\n",
        "        \n",
        "        self.model1 = ptcv_get_model(model_names[0], pretrained=True).to(device)\n",
        "        self.model2 = ptcv_get_model(model_names[1], pretrained=True).to(device)\n",
        "        self.model3 = ptcv_get_model(model_names[2], pretrained=True).to(device)\n",
        "        self.model4 = ptcv_get_model(model_names[3], pretrained=True).to(device)\n",
        "        self.model5 = ptcv_get_model(model_names[4], pretrained=True).to(device)\n",
        "        self.model6 = ptcv_get_model(model_names[5], pretrained=True).to(device)\n",
        "        self.model7 = ptcv_get_model(model_names[6], pretrained=True).to(device)\n",
        "        self.model8 = ptcv_get_model(model_names[7], pretrained=True).to(device)\n",
        "        self.model9 = ptcv_get_model(model_names[8], pretrained=True).to(device)\n",
        "        self.model10 = ptcv_get_model(model_names[9], pretrained=True).to(device)\n",
        "        self.model11 = ptcv_get_model(model_names[10], pretrained=True).to(device)\n",
        "        self.model12 = ptcv_get_model(model_names[11], pretrained=True).to(device)\n",
        "        self.model13 = ptcv_get_model(model_names[12], pretrained=True).to(device)\n",
        "        self.model14 = ptcv_get_model(model_names[13], pretrained=True).to(device)\n",
        "        self.model15 = ptcv_get_model(model_names[14], pretrained=True).to(device)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.model1(x.clone())\n",
        "        x2 = self.model2(x.clone())\n",
        "        x3 = self.model3(x.clone())\n",
        "        x4 = self.model4(x.clone())\n",
        "        x5 = self.model5(x.clone())\n",
        "        x6 = self.model6(x.clone())\n",
        "        x7 = self.model7(x.clone())\n",
        "        x8 = self.model8(x.clone())\n",
        "        x9 = self.model9(x.clone())\n",
        "        x10 = self.model10(x.clone())\n",
        "        x11 = self.model11(x.clone())\n",
        "        x12 = self.model12(x.clone())\n",
        "        x13 = self.model13(x.clone())\n",
        "        x14 = self.model14(x.clone())\n",
        "        x15 = self.model15(x.clone())\n",
        "\n",
        "        \n",
        "        x = (x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15)/ 15\n",
        "        \n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OE0mN1hZc-MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "\n",
        "model_names = [\n",
        "    'resnext29_16x64d_cifar10',\n",
        "    'resnext29_32x4d_cifar10',\n",
        "    'preresnet56_cifar10',\n",
        "    'preresnet110_cifar10',\n",
        "    'sepreresnet110_cifar10',\n",
        "    'preresnet164bn_cifar10',\n",
        "    'sepreresnet56_cifar10',\n",
        "    'seresnet110_cifar10',\n",
        "    'diaresnet56_cifar10',\n",
        "    'resnet1001_cifar10',\n",
        "    'diapreresnet56_cifar10',\n",
        "    'resnet1202_cifar10',\n",
        "    'resnet56_cifar10',\n",
        "    'resnet110_cifar10',\n",
        "    'diapreresnet110_cifar10\n",
        "    ]\n",
        "\n",
        "model = ensembleNet(model_names, device=device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for model_name in model_names:\n",
        "  model_checker(model_name)\n",
        "\n",
        "benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
        "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Z1DLzrdBly",
        "outputId": "85563cf0-44ad-42d6-dbc2-f78387f854d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benign_acc = 0.96000, benign_loss = 0.10345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FGSM"
      ],
      "metadata": {
        "id": "-CWEsxsUD0Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n",
        "print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n",
        "\n",
        "create_dir(root, 'ifgsm', adv_examples, adv_names)"
      ],
      "metadata": {
        "id": "xP6s-MCODyyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ifgsm\n",
        "!tar zcvf ../ifgsm.tgz *\n",
        "%cd .."
      ],
      "metadata": {
        "id": "lx-X40vrD3S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('ifgsm.tgz')"
      ],
      "metadata": {
        "id": "--9YWbhn_Evr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIFGSM"
      ],
      "metadata": {
        "id": "Qt1jIN2zDLX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv_examples, mifgsm_acc, mifgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n",
        "print(f'mifgsm_acc = {mifgsm_acc:.5f}, mifgsm_loss = {mifgsm_loss:.5f}')\n",
        "\n",
        "create_dir(root, 'mifgsm', adv_examples, adv_names)"
      ],
      "metadata": {
        "id": "XBaecGdkDLYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mifgsm\n",
        "!tar zcvf ../mifgsm.tgz *\n",
        "%cd .."
      ],
      "metadata": {
        "id": "sd8aJkv-DLYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('mifgsm.tgz')"
      ],
      "metadata": {
        "id": "Mgn-LuSpDLYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of Ensemble Attack\n",
        "* Ensemble multiple models as your proxy model to increase the black-box transferability ([paper](https://arxiv.org/abs/1611.02770))"
      ],
      "metadata": {
        "id": "7dq5LDvJD5rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################ BOSS BASELINE ######################\n",
        "\n",
        "class ensembleNet(nn.Module):\n",
        "    def __init__(self, model_names):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleList([ptcv_get_model(name, pretrained=True) for name in model_names])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #################### TODO: boss baseline ###################\n",
        "        ensemble_logits = None\n",
        "        for i, m in enumerate(self.models):\n",
        "          emsemble_logits = m(x) if i == 0 else emsemble_logits + m(x)\n",
        "        ensemble_logits /=  len(self.models)\n",
        "        # TODO: sum up logits from multiple models  \n",
        "        return ensemble_logits"
      ],
      "metadata": {
        "id": "nvEX_IM8D7Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Construct your ensemble model"
      ],
      "metadata": {
        "id": "De5J9n3WD-56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = [\n",
        "    'nin_cifar10',\n",
        "    #'resnet1202_cifar10',\n",
        "    #'preresnet110_cifar10', \n",
        "    #'seresnet272bn_cifar10',\n",
        "]\n",
        "\n",
        "for model_name in model_names:\n",
        "  model_checker(model_name)\n",
        "\n",
        "ensemble_model = ensembleNet(model_names).to(device)\n",
        "ensemble_model.eval()"
      ],
      "metadata": {
        "id": "9as1WHEiD_cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "4N6Me0GQECfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10, 20))\n",
        "cnt = 0\n",
        "for i, cls_name in enumerate(classes):\n",
        "    path = f'{cls_name}/{cls_name}1.png'\n",
        "    # benign image\n",
        "    cnt += 1\n",
        "    plt.subplot(len(classes), 4, cnt)\n",
        "    im = Image.open(f'./data/{path}')\n",
        "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "    predict = logit.argmax(-1).item()\n",
        "    prob = logit.softmax(-1)[predict].item()\n",
        "    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.array(im))\n",
        "    # adversarial image\n",
        "    cnt += 1\n",
        "    plt.subplot(len(classes), 4, cnt)\n",
        "    im = Image.open(f'./mifgsm/{path}')\n",
        "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "    predict = logit.argmax(-1).item()\n",
        "    prob = logit.softmax(-1)[predict].item()\n",
        "    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.array(im))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RxNrXHKsEDGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report Question\n",
        "* Make sure you follow below setup: the source model is \"resnet110_cifar10\", applying the vanilla fgsm attack on `dog2.png`. You can find the perturbed image in `fgsm/dog2.png`."
      ],
      "metadata": {
        "id": "WDc6QllJEHiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original image\n",
        "path = f'dog/dog2.png'\n",
        "im = Image.open(f'./data/{path}')\n",
        "logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "predict = logit.argmax(-1).item()\n",
        "prob = logit.softmax(-1)[predict].item()\n",
        "plt.title(f'benign: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(im))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# adversarial image \n",
        "adv_im = Image.open(f'./fgsm/{path}')\n",
        "logit = model(transform(adv_im).unsqueeze(0).to(device))[0]\n",
        "predict = logit.argmax(-1).item()\n",
        "prob = logit.softmax(-1)[predict].item()\n",
        "plt.title(f'adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(adv_im))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XhFVWA6JEH8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passive Defense - JPEG compression\n",
        "JPEG compression by imgaug package, compression rate set to 70\n",
        "\n",
        "Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression\n",
        "\n",
        "Note: If you haven't implemented the JPEG compression, this module will return an error. Don't worry about this."
      ],
      "metadata": {
        "id": "NfwhnywXEMwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# pre-process image\n",
        "x = transforms.ToTensor()(adv_im)*255\n",
        "x = x.permute(1, 2, 0).numpy()\n",
        "x = x.astype(np.uint8)\n",
        "\n",
        "# TODO: use \"imgaug\" package to perform JPEG compression (compression rate = 70)\n",
        "#compressed_x = iaa.JpegCompression(compression = 70) \n",
        "# ref : chatgpt\n",
        "seq = iaa.Sequential([\n",
        "    iaa.JpegCompression(compression=(70, 70))\n",
        "])\n",
        "compressed_x = seq.augment_image(x)\n",
        "\n",
        "logit = model(transform(compressed_x).unsqueeze(0).to(device))[0]\n",
        "predict = logit.argmax(-1).item()\n",
        "prob = logit.softmax(-1)[predict].item()\n",
        "plt.title(f'JPEG adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.imshow(compressed_x)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y2T7-L-BEKYg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}